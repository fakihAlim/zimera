{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengenali Intensi\n",
    "Intensi atau maksud adalah sesuatu yang menjadi tujuan yang ingin dicapai. Sebenarnya, memahami intensi merupakan hal yang rumit karena sifatnya multimodal atau terungkap dari banyak sisi serta ada sisi yang kemungkinan tersembunyi. Mengenali intensi di NLP tidak dimaksudkan sampai ke tingkat seperti seorang manusia memahami maksud dari manusia lain, tetapi hanya pada tingkatan mengetahui maksud dari apa yang terucap / tertulis.\n",
    "\n",
    "Pada dasarnya, ada beberapa teknik untuk mengenali intensi:\n",
    "\n",
    "1. Ekstraksi transitive verb (kata kerja transitif - kata kerja yang memerlukan obyek) dan direct object.\n",
    "2. Rangkaian kalimat - Konjungsi\n",
    "3. Mengenali sinonim untuk kemungkinan intensi yang berbeda-beda\n",
    "4. Menggunakan Semantic Similarity.\n",
    "5. Mengenali intensi dari urutan kalimat\n",
    "\n",
    "### Ekstraksi transitive verb (kata kerja transitif - kata kerja yang memerlukan obyek) dan direct object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cookedBaso\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#doc = nlp(u'show me the best hotel in berlin') #showHotel\n",
    "#doc = nlp (\"get me to the best hotel in town\") #getMe\n",
    "#doc = nlp (\"Yodi is the handsome man in all the town, He makes woman like crazy\") #makes woman\n",
    "doc = nlp (\"Joni cooked baso every day\")\n",
    "\n",
    "for token in doc:\n",
    "    if token.dep_ == 'dobj':\n",
    "        print(token.head.text + token.text.capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'direct object'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"dobj\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rangkaian Kalimat - Konjungsi\n",
    "Dilakukan dengan mengenali konjungsi, yaitu kata yang berfungsi untuk mengkoneksikan 2 suatu kata / sekumpulan kata (atau kalimat) dengan kata / sekumpulan kata (atau kalimat) sebelumnya. Contoh:\n",
    "\n",
    "- Pizza and Cola\n",
    "- Take two of these and call me in the morning\n",
    "- He has no money. In addition, he has no means of getting any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp(u'David repaired his car ')\n",
    "#doc = nlp(u'He has no money. In addition, he has no means of getting any')\n",
    "\n",
    "#extract the direct object and the conjunct associated with it\n",
    "for token in doc:\n",
    "    if token.dep_ == 'dobj':\n",
    "        dobj = [token.text]\n",
    "        conj = [t.text for t in token.conjuncts]\n",
    "\n",
    "#compose the list of the extracted elements\n",
    "dobj_conj = dobj + conj\n",
    "print(dobj_conj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conjunct'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"conj\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'back', '!']\n"
     ]
    }
   ],
   "source": [
    "#Bisa juga dengan menggunakan children. Contoh penggunaan children dari token:\n",
    "doc = nlp(\"Give it back! He pleaded.\")\n",
    "give_children = doc[0].children\n",
    "print ([t.text for t in give_children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ball']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#doc = nlp(u'I want a pizza and cola.')\n",
    "doc = nlp(u'Marjoko kicked the Ball')\n",
    "\n",
    "#extract the direct object and the conjunct associated with it\n",
    "for token in doc:\n",
    "    if token.dep_ == 'dobj':\n",
    "        dobj = [token.text]\n",
    "        conj = [t.text for t in token.children if t.dep_ == 'conj']\n",
    "\n",
    "#compose the list of the extracted elements\n",
    "dobj_conj = dobj + conj\n",
    "print(dobj_conj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada kasus-kasus tertentu, token selain transitive verb dan direct object. Token-token tersebut biasanya terkait dengan transitive verb dan direct object, sehingga harus dieksplorasi relasi sintaksis dengan transitive verb dan direct object. Kode sumber berikut melakukan proses analisis tersebut dan melakukan perbandingan dengan daftar kata yang sudah dibuat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wantPizza\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#apply the pipeline to the sample sentence\n",
    "doc = nlp(u'I want to place an order for a pizza.')\n",
    "\n",
    "\n",
    "# extract the direct object and its transitive verb\n",
    "dobj = ''\n",
    "tverb = ''\n",
    "for token in doc:\n",
    "    if token.dep_ == 'dobj':\n",
    "        dobj = token\n",
    "        tverb = token.head\n",
    "\n",
    "# extract the verb for the intent's definition\n",
    "intentVerb = ''\n",
    "verbList = ['want', 'like', 'need', 'order']\n",
    "if tverb.text in verbList:\n",
    "    intentVerb = tverb\n",
    "else:\n",
    "    if tverb.head.dep_ == 'ROOT':\n",
    "        intentVerb = tverb.head\n",
    "\n",
    "# extract the object for the intent's definition\n",
    "intentObj = ''\n",
    "objList = ['pizza', 'cola']\n",
    "if dobj.text in objList:\n",
    "    intentObj = dobj\n",
    "else:\n",
    "    for child in dobj.children:\n",
    "        if child.dep_ == 'prep':\n",
    "            intentObj = list(child.children)[0]\n",
    "            break\n",
    "        elif child.dep_ == 'compound':\n",
    "            intentObj = child\n",
    "            break\n",
    "\n",
    "# print the intent expressed in the sample sentence\n",
    "print(intentVerb.text + intentObj.text.capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengenali Sinonim\n",
    "Sering terjadi, ekspresi dilakukan dengan menggunakan kata-kata dengan intensi yang sama. Contoh, lihat pada 3 kalimat pada aplikasi chatbot pemesanan pizza:\n",
    "\n",
    "1. I want a dish\n",
    "2. I'd like to order a pizza\n",
    "3. Give me a pie\n",
    "\n",
    "Ketiganya mengandung intensi yang sama, yaitu **orderPizza**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orderPizza\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp(u'I want a dish.')\n",
    "\n",
    "#extract the transitive verb and its direct object from the dependency tree\n",
    "for token in doc:\n",
    "    if token.dep_ == 'dobj':\n",
    "        verb = token.head.text\n",
    "        dobj = token.text\n",
    "\n",
    "#create a list of tuples for possible verb synonyms\n",
    "verbList = [('order','want','give','make'),('show','find')]\n",
    "\n",
    "#find the tuple containing the transitive verb extracted from the sample\n",
    "verbSyns = [item for item in verbList if verb in item]\n",
    "\n",
    "#create a list of tuples for possible direct object synonyms\n",
    "dobjList = [('pizza','pie','dish'),('cola','soda')]\n",
    "\n",
    "#find the tuple containing the direct object extracted from the sample\n",
    "dobjSyns = [item for item in dobjList if dobj in item]\n",
    "\n",
    "#replace the transitive verb and the direct object with synonyms supported by the application\n",
    "#and compose the string that represents the intent\n",
    "intent = verbSyns[0][0] + dobjSyns[0][0].capitalize()\n",
    "print(intent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagaimana jika kata tidak terdapat pada list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('order', 'want', 'give', 'make')]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp(u'I want an apple.')\n",
    "\n",
    "#extract the transitive verb and its direct object from the dependency tree\n",
    "for token in doc:\n",
    "    if token.dep_ == 'dobj':\n",
    "        verb = token.head.text\n",
    "        dobj = token.text\n",
    "\n",
    "#create a list of tuples for possible verb synonyms\n",
    "verbList = [('order','want','give','make'),('show','find')]\n",
    "\n",
    "#find the tuple containing the transitive verb extracted from the sample\n",
    "verbSyns = [item for item in verbList if verb in item]\n",
    "\n",
    "#create a list of tuples for possible direct object synonyms\n",
    "dobjList = [('pizza','pie','dish'),('cola','soda')]\n",
    "\n",
    "#find the tuple containing the direct object extracted from the sample\n",
    "dobjSyns = [item for item in dobjList if dobj in item]\n",
    "\n",
    "print(verbSyns)\n",
    "print(dobjSyns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like to look at our menu?\n",
      "0.45949376\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "doc = nlp(u'I feel like eating a pie')\n",
    "doc2 = nlp(u'food')\n",
    "\n",
    "for token in doc:\n",
    "    if token.dep_ == 'dobj':\n",
    "        dobj = token\n",
    "\n",
    "if dobj.similarity(doc2[0]) > 0.4:\n",
    "    print(\"Would you like to look at our menu?\")\n",
    "\n",
    "print(dobj.similarity(doc2[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengenali Intensi dari Urutan Kalimat\n",
    "Contoh: \"I have finished my pizza. I want another one\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orderPizza\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp(u'I have finished my pizza. I want another one.')\n",
    "\n",
    "verbList = [('order','want','give','make'),('show','find')]\n",
    "dobjList = [('pizza','pie','pizzaz'),('cola','soda')]\n",
    "substitutes = ('one','it','same','more')\n",
    "intent = {'verb': '', 'dobj': ''}\n",
    "\n",
    "for sent in doc.sents:\n",
    "    for token in sent:\n",
    "        if token.dep_ == 'dobj':\n",
    "            verbSyns = [item for item in verbList if token.head.text in item]\n",
    "            dobjSyns = [item for item in dobjList if token.text in item]\n",
    "            substitute = [item for item in substitutes if token.text in item]\n",
    "            if (dobjSyns != [] or substitute != []) and verbSyns != []:\n",
    "                intent['verb'] = verbSyns[0][0]\n",
    "            if dobjSyns != []:\n",
    "                intent['dobj'] = dobjSyns[0][0]\n",
    "\n",
    "intentStr = intent['verb'] + intent['dobj'].capitalize()\n",
    "print(intentStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b03c103e43e670ae080ce36f4c3aadf0b7d2fc5c8142e5a07a36765ec3b5d6c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
