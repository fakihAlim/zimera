{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processing Pilienes\n",
    "text -> nlp -> Doc. Yang akan menghasilkan token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hallo\n",
      "world\n",
      "!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nSetelah proses ini baru dapat dilakukan berbagai macam pemrosessan.\\nInfo lengkap processing pipelines (https://spacy.io/usage/processing-pipelines)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "doc = nlp(\"Hallo world!\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "\n",
    "'''\n",
    "Setelah proses ini baru dapat dilakukan berbagai macam pemrosessan.\n",
    "Info lengkap processing pipelines (https://spacy.io/usage/processing-pipelines)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "Lemmatization adalah proses untuk mencari bentuk kata dasar. Proses ini dilaksanakan oleh lemmatizer. Pada spaCy, lemmatizer dilakukan oleh komponen lemmatizer. Informasi lengkap ada di https://spacy.io/api/lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this this\n",
      "product product\n",
      "integrates integrate\n",
      "both both\n",
      "libraries library\n",
      "for for\n",
      "downloading download\n",
      "and and\n",
      "applying apply\n",
      "patches patch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nPerhatikan, lemmatization ini bisa menjadi titik awal dari intent recognition. \\nMisal kita akan memproses masukan dari user yang akan membeli tiket. \\nTiket bisa berupa tiket bis, pesawat, maupun kendaraan lain. Dengan demikian, diperlukan data tentang:\\n\\n1. Kendaraan yang diinginkan: fly => terbang, naik pesawat\\n2. Kemana? => to menunjukkan tujuan\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(u'this product integrates both libraries for downloading and applying patches')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_)\n",
    "\n",
    "\n",
    "'''\n",
    "Perhatikan, lemmatization ini bisa menjadi titik awal dari intent recognition. \n",
    "Misal kita akan memproses masukan dari user yang akan membeli tiket. \n",
    "Tiket bisa berupa tiket bis, pesawat, maupun kendaraan lain. Dengan demikian, diperlukan data tentang:\n",
    "\n",
    "1. Kendaraan yang diinginkan: fly => terbang, naik pesawat\n",
    "2. Kemana? => to menunjukkan tujuan\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['token:I lemma:I', 'token:am lemma:be', 'token:flying lemma:fly', 'token:to lemma:to', 'token:Frisco lemma:San Francisco']\n"
     ]
    }
   ],
   "source": [
    "# orth is simply an integer that indicates \n",
    "# the index of the occurrence of the word that \n",
    "# is kept in the spacy. tokens\n",
    "\n",
    "from spacy.symbols import LOWER, LEMMA\n",
    "\n",
    "nlp.get_pipe(\"attribute_ruler\").add([[{\"LOWER\": \"frisco\"}]], {\"LEMMA\": \"San Francisco\"})\n",
    "doc = nlp(u'I am flying to Frisco')\n",
    "\n",
    "print(['token:%s lemma:%s' % (t.text, t.lemma_) for t in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagger\n",
    "\n",
    "Merupakan komponen untuk PoS Tagging. Dokumentasi lengkap: https://spacy.io/api/tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token:I lemma:I pos:PRON tag:PRP\n",
      "token:have lemma:have pos:AUX tag:VBP\n",
      "token:flown lemma:fly pos:VERB tag:VBN\n",
      "token:to lemma:to pos:ADP tag:IN\n",
      "token:LA lemma:LA pos:PROPN tag:NNP\n",
      "token:. lemma:. pos:PUNCT tag:.\n",
      "token:Now lemma:now pos:ADV tag:RB\n",
      "token:I lemma:I pos:PRON tag:PRP\n",
      "token:am lemma:be pos:AUX tag:VBP\n",
      "token:flying lemma:fly pos:VERB tag:VBG\n",
      "token:to lemma:to pos:ADP tag:IN\n",
      "token:Frisco lemma:San Francisco pos:PROPN tag:NNP\n"
     ]
    }
   ],
   "source": [
    "nlp.get_pipe(\"attribute_ruler\").add([[{\"LOWER\": \"frisco\"}]], {\"LEMMA\": \"San Francisco\"})\n",
    "\n",
    "doc = nlp(u'I have flown to LA. Now I am flying to Frisco')\n",
    "\n",
    "for t in doc:\n",
    "    print('token:%s lemma:%s pos:%s tag:%s' % (t.text, t.lemma_, t.pos_, t.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pronoun'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"PRON\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pronoun, personal'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"PRP\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'auxiliary'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"AUX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'verb, non-3rd person singular present'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"VBP\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'verb, past participle'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"VBN\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adposition'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"ADP\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conjunction, subordinating or preposition'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"IN\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proper noun'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"PROPN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun, proper singular'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"NNP\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'punctuation'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"PUNCT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adverb'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"ADV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adverb'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"RB\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'verb'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"VERB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'verb, gerund or present participle'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"VBG\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token:I lemma:I pos:PRON dep:nsubj\n",
      "token:have lemma:have pos:AUX dep:aux\n",
      "token:flown lemma:fly pos:VERB dep:ROOT\n",
      "token:to lemma:to pos:ADP dep:prep\n",
      "token:LA lemma:LA pos:PROPN dep:pobj\n",
      "token:. lemma:. pos:PUNCT dep:punct\n",
      "token:Now lemma:now pos:ADV dep:advmod\n",
      "token:I lemma:I pos:PRON dep:nsubj\n",
      "token:am lemma:be pos:AUX dep:aux\n",
      "token:flying lemma:fly pos:VERB dep:ROOT\n",
      "token:to lemma:to pos:ADP dep:prep\n",
      "token:Frisco lemma:San Francisco pos:PROPN dep:pobj\n"
     ]
    }
   ],
   "source": [
    "for t in doc:\n",
    "    print('token:%s lemma:%s pos:%s dep:%s' % (t.text, t.lemma_, t.pos_, t.dep_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token head text:flown dependency:nsubj text:I\n",
      "token head text:flown dependency:aux text:have\n",
      "token head text:flown dependency:ROOT text:flown\n",
      "token head text:flown dependency:prep text:to\n",
      "token head text:to dependency:pobj text:LA\n",
      "token head text:flown dependency:punct text:.\n",
      "token head text:flying dependency:advmod text:Now\n",
      "token head text:flying dependency:nsubj text:I\n",
      "token head text:flying dependency:aux text:am\n",
      "token head text:flying dependency:ROOT text:flying\n",
      "token head text:flying dependency:prep text:to\n",
      "token head text:to dependency:pobj text:Frisco\n"
     ]
    }
   ],
   "source": [
    "for t in doc:\n",
    "    print('token head text:%s dependency:%s text:%s' % (t.head.text, t.dep_, t.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flown', 'LA']\n",
      "['flying', 'Frisco']\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print([w.text for w in sent if w.dep_ == 'ROOT' or w.dep_ == 'pobj'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER (Named Entity Recognition)\n",
    "Informasi lengkap: https://spacy.io/api/entityrecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LA GPE\n",
      "San Francisco ORG\n"
     ]
    }
   ],
   "source": [
    "nlp.get_pipe(\"attribute_ruler\").add([[{\"LOWER\": \"frisco\"}]], {\"LEMMA\": \"San Francisco\"})\n",
    "\n",
    "doc = nlp(u'I have flown to LA. Now I am flying to Frisco')\n",
    "\n",
    "for token in doc:\n",
    "    if token.ent_type != 0:\n",
    "        print(token.lemma_, token.ent_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1dbe5302cb3bb4c0fe4e492535fb181d3f49e6b02a7d389fb2104bcbd574eaf4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('py39-nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
